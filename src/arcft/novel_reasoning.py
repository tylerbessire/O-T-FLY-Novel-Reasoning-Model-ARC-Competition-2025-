#!/usr/bin/env python3
"""
Novel Reasoning Engine with Meta-Cognition and Philosophical Character Compartmentalization

This script implements advanced reasoning capabilities including:
- Meta-cognition and self-reflection
- Philosophical character compartmentalization for different thinking modes
- Hypothesis generation before answering
- Rule abstraction and learning
- Dual-answer generation for improved accuracy
- Future simulation of potential answers
"""

import os
import json
import asyncio
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime
import openai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ReasoningStep:
    """Represents a single step in the reasoning process"""
    step_id: str
    character: str
    thought: str
    hypothesis: Optional[str] = None
    confidence: float = 0.0
    timestamp: str = ""

@dataclass
class Rule:
    """Represents a learned rule or pattern"""
    rule_id: str
    description: str
    pattern: str
    confidence: float
    usage_count: int
    created_at: str
    last_used: str
    success_rate: float

@dataclass
class DualAnswer:
    """Represents two different approaches to the same problem"""
    primary_answer: str
    alternative_answer: str
    primary_confidence: float
    alternative_confidence: float
    reasoning_comparison: str
    recommended_answer: str

class PhilosophicalCharacter:
    """Represents a philosophical character with specific thinking patterns"""
    
    def __init__(self, name: str, description: str, thinking_style: str, expertise: List[str]):
        self.name = name
        self.description = description
        self.thinking_style = thinking_style
        self.expertise = expertise
        self.personality_prompt = self._generate_personality_prompt()
    
    def _generate_personality_prompt(self) -> str:
        return f"""You are {self.name}, {self.description}. 
Your thinking style: {self.thinking_style}
Areas of expertise: {', '.join(self.expertise)}

When approaching problems, you should:
1. Think like {self.name} would naturally think
2. Apply your unique perspective and expertise
3. Consider problems through your philosophical lens
4. Generate hypotheses based on your worldview
5. Express your thoughts in your characteristic manner

Remember: You are not just simulating {self.name}, you ARE {self.name} in this moment."""

class NovelReasoningEngine:
    """Advanced reasoning engine with meta-cognition and character compartmentalization"""
    
    def __init__(self, api_key: str, model: str = "gpt-5"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.model = model
        self.rules: List[Rule] = []
        self.reasoning_history: List[ReasoningStep] = []
        self.characters = self._initialize_philosophical_characters()
        self.rule_storage_file = "learned_rules.json"
        self._load_existing_rules()
    
    def _initialize_philosophical_characters(self) -> Dict[str, PhilosophicalCharacter]:
        """Initialize the philosophical characters for compartmentalized thinking"""
        return {
            "socrates": PhilosophicalCharacter(
                name="Socrates",
                description="Ancient Greek philosopher known for the Socratic method",
                thinking_style="Questioning, dialectical, seeking definitions and clarity through systematic inquiry",
                expertise=["logic", "ethics", "epistemology", "critical thinking", "questioning assumptions"]
            ),
            "aristotle": PhilosophicalCharacter(
                name="Aristotle",
                description="Ancient Greek philosopher and scientist, student of Plato",
                thinking_style="Systematic, empirical, categorizing, seeking causes and principles",
                expertise=["logic", "metaphysics", "ethics", "politics", "natural sciences", "categorization"]
            ),
            "descartes": PhilosophicalCharacter(
                name="RenÃ© Descartes",
                description="French philosopher and mathematician, father of modern philosophy",
                thinking_style="Analytical, mathematical, systematic doubt, seeking certainty",
                expertise=["mathematics", "metaphysics", "epistemology", "methodology", "systematic reasoning"]
            ),
            "kant": PhilosophicalCharacter(
                name="Immanuel Kant",
                description="German philosopher, central figure in modern philosophy",
                thinking_style="Critical, systematic, seeking universal principles and conditions of possibility",
                expertise=["epistemology", "ethics", "metaphysics", "aesthetics", "transcendental philosophy"]
            ),
            "nietzsche": PhilosophicalCharacter(
                name="Friedrich Nietzsche",
                description="German philosopher, critic of traditional morality and religion",
                thinking_style="Perspectival, genealogical, questioning traditional values, creative destruction",
                expertise=["ethics", "aesthetics", "philosophy of history", "critique of morality", "creative thinking"]
            )
        }
    
    def _load_existing_rules(self):
        """Load previously learned rules from storage"""
        try:
            if os.path.exists(self.rule_storage_file):
                with open(self.rule_storage_file, 'r') as f:
                    rules_data = json.load(f)
                    self.rules = [Rule(**rule) for rule in rules_data]
                logger.info(f"Loaded {len(self.rules)} existing rules")
        except Exception as e:
            logger.warning(f"Could not load existing rules: {e}")
    
    def _save_rules(self):
        """Save learned rules to storage"""
        try:
            with open(self.rule_storage_file, 'w') as f:
                json.dump([asdict(rule) for rule in self.rules], f, indent=2)
            logger.info(f"Saved {len(self.rules)} rules to storage")
        except Exception as e:
            logger.error(f"Could not save rules: {e}")
    
    async def _generate_character_thought(self, character: PhilosophicalCharacter, 
                                        problem: str, context: str = "") -> str:
        """Generate a thought from a specific philosophical character's perspective"""
        
        prompt = f"""{character.personality_prompt}

PROBLEM TO ANALYZE:
{problem}

CONTEXT (if any):
{context}

Based on your philosophical perspective and expertise, analyze this problem. 
Think step by step, generate hypotheses, and express your reasoning.

Your analysis:"""

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_completion_tokens=1000
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"Error generating thought for {character.name}: {e}")
            return f"Error in {character.name}'s analysis: {str(e)}"
    
    async def _generate_hypothesis(self, problem: str, character_thoughts: Dict[str, str]) -> str:
        """Generate hypotheses based on character thoughts"""
        
        thoughts_summary = "\n".join([f"{char}: {thought}" for char, thought in character_thoughts.items()])
        
        prompt = f"""Based on the following philosophical perspectives on the problem, generate 3-5 specific hypotheses:

PROBLEM: {problem}

PHILOSOPHICAL PERSPECTIVES:
{thoughts_summary}

Generate hypotheses that:
1. Are specific and testable
2. Consider multiple perspectives
3. Build on the philosophical insights
4. Could explain the observed patterns

Your hypotheses:"""

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.8,
                max_completion_tokens=800
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"Error generating hypotheses: {e}")
            return f"Error generating hypotheses: {str(e)}"
    
    async def _simulate_future_answers(self, problem: str, hypotheses: str, 
                                     character_thoughts: Dict[str, str]) -> Tuple[str, str]:
        """Simulate two different approaches to answering the problem"""
        
        context = f"""
PROBLEM: {problem}

HYPOTHESES: {hypotheses}

PHILOSOPHICAL INSIGHTS: {json.dumps(character_thoughts, indent=2)}

Generate TWO different approaches to solving this problem:

APPROACH 1: Use a systematic, analytical method
APPROACH 2: Use a creative, intuitive method

For each approach, provide:
- Your reasoning process
- The solution you arrive at
- Your confidence level (0-1)
- Why this approach might be better than the other

Format your response clearly separating the two approaches."""

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": context}],
                temperature=0.9,
                max_completion_tokens=1500
            )
            content = response.choices[0].message.content.strip()
            
            # Split into two approaches (simple heuristic)
            lines = content.split('\n')
            mid_point = len(lines) // 2
            approach1 = '\n'.join(lines[:mid_point])
            approach2 = '\n'.join(lines[mid_point:])
            
            return approach1, approach2
        except Exception as e:
            logger.error(f"Error simulating future answers: {e}")
            return f"Error in approach 1: {str(e)}", f"Error in approach 2: {str(e)}"
    
    async def _abstract_rules(self, problem: str, solution: str, 
                             character_thoughts: Dict[str, str]) -> List[Rule]:
        """Abstract general rules from the problem-solving process"""
        
        prompt = f"""Based on this problem-solving session, identify 2-4 general rules or patterns that could be applied to similar problems in the future.

PROBLEM: {problem}
SOLUTION: {solution}
THOUGHT PROCESS: {json.dumps(character_thoughts, indent=2)}

For each rule, provide:
1. A clear description of the pattern
2. The specific pattern or rule
3. Your confidence in this rule (0-1)
4. When this rule would be applicable

Format as a structured list."""

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_completion_tokens=1000
            )
            
            # Parse the response to extract rules
            content = response.choices[0].message.content.strip()
            rules = self._parse_rules_from_response(content)
            
            # Add metadata
            timestamp = datetime.now().isoformat()
            for rule in rules:
                rule.created_at = timestamp
                rule.last_used = timestamp
                rule.usage_count = 1
                rule.success_rate = 0.8  # Initial estimate
            
            return rules
        except Exception as e:
            logger.error(f"Error abstracting rules: {e}")
            return []
    
    def _parse_rules_from_response(self, response: str) -> List[Rule]:
        """Parse rules from the AI response"""
        rules = []
        lines = response.split('\n')
        
        current_rule = {}
        for line in lines:
            line = line.strip()
            if line.startswith('1.') or line.startswith('2.') or line.startswith('3.') or line.startswith('4.'):
                if current_rule:
                    rules.append(Rule(**current_rule))
                current_rule = {
                    'rule_id': f"rule_{len(rules)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    'description': '',
                    'pattern': '',
                    'confidence': 0.8,
                    'usage_count': 1,
                    'created_at': '',
                    'last_used': '',
                    'success_rate': 0.8
                }
            elif 'description:' in line.lower():
                current_rule['description'] = line.split(':', 1)[1].strip()
            elif 'pattern:' in line.lower() or 'rule:' in line.lower():
                current_rule['pattern'] = line.split(':', 1)[1].strip()
            elif 'confidence:' in line.lower():
                try:
                    conf_str = line.split(':', 1)[1].strip()
                    current_rule['confidence'] = float(conf_str)
                except:
                    pass
        
        if current_rule:
            rules.append(Rule(**current_rule))
        
        return rules
    
    async def solve_problem(self, problem: str, context: str = "") -> Dict[str, Any]:
        """Main method to solve a problem using novel reasoning"""
        
        logger.info(f"Starting novel reasoning process for problem: {problem[:100]}...")
        
        # Step 1: Generate thoughts from different philosophical perspectives
        character_thoughts = {}
        for char_name, character in self.characters.items():
            logger.info(f"Generating thought from {character.name}'s perspective...")
            thought = await self._generate_character_thought(character, problem, context)
            character_thoughts[char_name] = thought
            
            # Record reasoning step
            step = ReasoningStep(
                step_id=f"step_{len(self.reasoning_history)}_{char_name}",
                character=char_name,
                thought=thought,
                timestamp=datetime.now().isoformat()
            )
            self.reasoning_history.append(step)
        
        # Step 2: Generate hypotheses
        logger.info("Generating hypotheses based on philosophical insights...")
        hypotheses = await self._generate_hypothesis(problem, character_thoughts)
        
        # Step 3: Simulate future answers
        logger.info("Simulating different approaches to the problem...")
        approach1, approach2 = await self._simulate_future_answers(problem, hypotheses, character_thoughts)
        
        # Step 4: Generate final dual answers
        logger.info("Generating final dual answers...")
        dual_answer = await self._generate_dual_answers(problem, approach1, approach2, character_thoughts)
        
        # Step 5: Abstract rules
        logger.info("Abstracting general rules from the solution...")
        new_rules = await self._abstract_rules(problem, dual_answer.recommended_answer, character_thoughts)
        
        # Add new rules to storage
        self.rules.extend(new_rules)
        self._save_rules()
        
        # Compile results
        result = {
            "problem": problem,
            "context": context,
            "timestamp": datetime.now().isoformat(),
            "character_thoughts": character_thoughts,
            "hypotheses": hypotheses,
            "dual_answers": asdict(dual_answer),
            "new_rules_learned": len(new_rules),
            "total_rules": len(self.rules),
            "reasoning_steps": len(self.reasoning_history)
        }
        
        logger.info(f"Novel reasoning completed. Generated {len(new_rules)} new rules.")
        return result
    
    async def _generate_dual_answers(self, problem: str, approach1: str, approach2: str, 
                                   character_thoughts: Dict[str, str]) -> DualAnswer:
        """Generate the final dual answers with comparison"""
        
        prompt = f"""Based on the two approaches below, provide the final dual answers:

PROBLEM: {problem}

APPROACH 1: {approach1}

APPROACH 2: {approach2}

PHILOSOPHICAL INSIGHTS: {json.dumps(character_thoughts, indent=2)}

Provide:
1. PRIMARY ANSWER: The most likely correct solution
2. ALTERNATIVE ANSWER: A different but plausible solution
3. Confidence levels for each (0-1)
4. Reasoning comparison explaining why you chose these answers
5. RECOMMENDED ANSWER: Which one to use and why

Format your response clearly."""

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_completion_tokens=1200
            )
            
            content = response.choices[0].message.content.strip()
            
            # Parse the response to extract dual answers
            dual_answer = self._parse_dual_answers_from_response(content)
            return dual_answer
        except Exception as e:
            logger.error(f"Error generating dual answers: {e}")
            return DualAnswer(
                primary_answer="Error generating primary answer",
                alternative_answer="Error generating alternative answer",
                primary_confidence=0.0,
                alternative_confidence=0.0,
                reasoning_comparison="Error in dual answer generation",
                recommended_answer="Error"
            )
    
    def _parse_dual_answers_from_response(self, response: str) -> DualAnswer:
        """Parse dual answers from the AI response"""
        # Simple parsing - in practice, you might want more sophisticated parsing
        lines = response.split('\n')
        
        primary_answer = "Primary answer not found"
        alternative_answer = "Alternative answer not found"
        primary_confidence = 0.8
        alternative_confidence = 0.7
        reasoning_comparison = "Reasoning comparison not found"
        recommended_answer = "Recommended answer not found"
        
        for i, line in enumerate(lines):
            line = line.strip()
            if 'primary answer:' in line.lower():
                primary_answer = line.split(':', 1)[1].strip()
            elif 'alternative answer:' in line.lower():
                alternative_answer = line.split(':', 1)[1].strip()
            elif 'primary confidence:' in line.lower():
                try:
                    conf_str = line.split(':', 1)[1].strip()
                    primary_confidence = float(conf_str)
                except:
                    pass
            elif 'alternative confidence:' in line.lower():
                try:
                    conf_str = line.split(':', 1)[1].strip()
                    alternative_confidence = float(conf_str)
                except:
                    pass
            elif 'reasoning comparison:' in line.lower():
                reasoning_comparison = line.split(':', 1)[1].strip()
            elif 'recommended answer:' in line.lower():
                recommended_answer = line.split(':', 1)[1].strip()
        
        return DualAnswer(
            primary_answer=primary_answer,
            alternative_answer=alternative_answer,
            primary_confidence=primary_confidence,
            alternative_confidence=alternative_confidence,
            reasoning_comparison=reasoning_comparison,
            recommended_answer=recommended_answer
        )
    
    def get_learned_rules(self) -> List[Rule]:
        """Get all learned rules"""
        return self.rules
    
    def get_reasoning_history(self) -> List[ReasoningStep]:
        """Get reasoning history"""
        return self.reasoning_history
    
    def clear_history(self):
        """Clear reasoning history"""
        self.reasoning_history.clear()
        logger.info("Reasoning history cleared")

async def main():
    """Main function to demonstrate the novel reasoning engine"""
    
    # Check for API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("Error: OPENAI_API_KEY environment variable not set")
        print("Please set your OpenAI API key in a .env file or environment variable")
        return
    
    # Initialize the reasoning engine
    engine = NovelReasoningEngine(api_key)
    
    # Example problem
    problem = """
    You are given a grid where some cells are filled and some are empty. 
    The pattern seems to follow a rule where filled cells create a specific shape or follow a mathematical sequence.
    Your task is to determine the rule and predict what the next state of the grid should be.
    
    Current grid state:
    [X][ ][X]
    [ ][X][ ]
    [X][ ][X]
    
    What rule governs this pattern and what should the next state be?
    """
    
    print("ð§  Novel Reasoning Engine Starting...")
    print("=" * 60)
    print(f"Problem: {problem.strip()}")
    print("=" * 60)
    
    try:
        # Solve the problem
        result = await engine.solve_problem(problem)
        
        print("\nð¯ RESULTS:")
        print("=" * 60)
        
        print(f"\nð Character Thoughts:")
        for char, thought in result["character_thoughts"].items():
            print(f"\n{char.upper()}: {thought[:200]}...")
        
        print(f"\nð Hypotheses:")
        print(result["hypotheses"][:300] + "...")
        
        print(f"\nð¡ Dual Answers:")
        dual = result["dual_answers"]
        print(f"Primary: {dual['primary_answer']}")
        print(f"Alternative: {dual['alternative_answer']}")
        print(f"Primary Confidence: {dual['primary_confidence']}")
        print(f"Alternative Confidence: {dual['alternative_confidence']}")
        print(f"Recommended: {dual['recommended_answer']}")
        
        print(f"\nð New Rules Learned: {result['new_rules_learned']}")
        print(f"Total Rules: {result['total_rules']}")
        
        print(f"\nð Novel reasoning completed successfully!")
        
    except Exception as e:
        print(f"â Error during reasoning: {e}")
        logger.error(f"Error in main: {e}")

if __name__ == "__main__":
    asyncio.run(main())
